<h3 align="center"><a href="" style="color:#9C276A">
VLSA: Vision-Language-Action Models with Plug-and-Play Safety Constraint Layer</a></h3>
<h5 align="center"> If our project helps you, please give us a star â­ on GitHub to support us. ğŸ™ğŸ™ </h2>

To facilitate reproducibility and future research, we will make our code, models, and the benchmark datasets publicly available in the coming week. 

## ğŸ“¢ Updates

- **[Dec 2025]** ğŸ“… We plan to release the **SafeLIBERO benchmark** on **December 20**.
- **[Dec 9, 2025]** ğŸ”¥ Initial release of the **vlsa-aegis** repository.
