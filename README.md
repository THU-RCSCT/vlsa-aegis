<h1 align="center",style="font-size: 22px;"><a href="" style="color:#9C276A">
VLSA: Vision-Language-Action Models with Plug-and-Play Safety Constraint Layer</a></h1>
<h5 align="center"> If our project helps you, please give us a star â­ on GitHub to support us. ğŸ™ğŸ™ </h2>
<h5 align="center">

[![arXiv](https://img.shields.io/badge/Arxiv-2511.11891-AD1C18.svg?logo=arXiv)](https://arxiv.org/pdf/2512.11891) 
[![Website](https://img.shields.io/badge/Website-Project_Page-blue.svg?logo=googlechrome&logoColor=white)](https://vlsa-aegis.github.io/)
</h5> 

## SafeLIBERO Benchmark
<p align="center">
  <img src="https://github.com/songqiaohu/pictureandgif/blob/main/safelibero_overview.png?raw=true" alt="overview" width="600">
</p> 

## ğŸ“¢ Updates

- **[Dec 2025]** ğŸ“… We plan to release the **SafeLIBERO benchmark** on **December 20**.
- **[Dec 9, 2025]** ğŸ”¥ Initial release of the **vlsa-aegis** repository.
